{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCsIyB0mzfEVNYwPvgPbrp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prithivi1515/Demo/blob/main/Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "e2fBMstjSOmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a Decision Tree, and how does it work?\n"
      ],
      "metadata": {
        "id": "eSO5xpePSRoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. It splits the data into subsets based on the most significant feature at each node, creating a tree-like structure. The algorithm selects a feature and splits the dataset to minimize impurity or maximize information gain at each node. The process continues recursively until the tree reaches a stopping criterion, such as maximum depth or minimum sample size."
      ],
      "metadata": {
        "id": "HRgNYZmGSSB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are impurity measures in Decision Trees?\n"
      ],
      "metadata": {
        "id": "5ztD6vM4STqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impurity measures are used in Decision Trees to evaluate how well the features split the dataset. The goal is to select the feature that results in the most homogeneous subsets. Common impurity measures include:\n",
        "\n",
        "Gini Impurity\n",
        "\n",
        "Entropy"
      ],
      "metadata": {
        "id": "WsVyNjsbSU57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the mathematical formula for Gini Impurity?\n"
      ],
      "metadata": {
        "id": "BfT5x06KSWwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gini Impurity is a measure of how often a randomly chosen element would be misclassified. It is calculated using the following formula:\n",
        "\n",
        "\n",
        "Gini=1−\n",
        "i=1\n",
        "∑\n",
        "k\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "p\n",
        "i\n",
        "  is the probability of class\n",
        "i in the node.\n",
        "\n",
        "k is the number of classes.\n"
      ],
      "metadata": {
        "id": "gY4DLCzaSY35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the mathematical formula for Entropy?\n"
      ],
      "metadata": {
        "id": "tnLScWSwSoXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entropy is a measure of the disorder or impurity in the dataset. The formula for Entropy is:\n",
        "\n",
        "Entropy=−\n",
        "i=1\n",
        "∑\n",
        "k\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "​ is the probability of class\n",
        "i in the node.\n",
        "\n",
        "k is the number of classes."
      ],
      "metadata": {
        "id": "u0z0JT3KSrAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is Information Gain, and how is it used in Decision Trees?\n"
      ],
      "metadata": {
        "id": "biHrbi0DS1LM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Gain measures the effectiveness of an attribute in classifying the dataset. It is the difference between the entropy of the dataset before and after the split. The formula is:\n",
        "\n",
        "𝐼\n",
        "𝑛\n",
        "𝑓\n",
        "𝑜\n",
        "𝑟\n",
        "𝑚\n",
        "𝑎\n",
        "𝑡\n",
        "𝑖\n",
        "𝑜\n",
        "𝑛\n",
        "\n",
        "𝐺\n",
        "𝑎\n",
        "𝑖\n",
        "𝑛\n",
        "=\n",
        "𝐸\n",
        "𝑛\n",
        "𝑡\n",
        "𝑟\n",
        "𝑜\n",
        "𝑝\n",
        "𝑦\n",
        "(\n",
        "𝑆\n",
        ")\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑘\n",
        "∣\n",
        "𝑆\n",
        "𝑖\n",
        "∣\n",
        "∣\n",
        "𝑆\n",
        "∣\n",
        "⋅\n",
        "𝐸\n",
        "𝑛\n",
        "𝑡\n",
        "𝑟\n",
        "𝑜\n",
        "𝑝\n",
        "𝑦\n",
        "(\n",
        "𝑆\n",
        "𝑖\n",
        ")\n",
        "Where:\n",
        "\n",
        "S is the original set.\n",
        "S\n",
        " i\n",
        "​ are the subsets after splitting.\n",
        "∣\n",
        "𝑆\n",
        "∣\n",
        "∣S∣ is the total number of samples."
      ],
      "metadata": {
        "id": "JEzqXrsuS5JD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the difference between Gini Impurity and Entropy?\n"
      ],
      "metadata": {
        "id": "4USZ-0w-TJh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gini Impurity tends to favor larger partitions, so it may create more balanced splits.\n",
        "\n",
        "Entropy measures uncertainty, making it more sensitive to splits that reduce uncertainty. It often results in a more balanced tree.\n",
        "\n",
        "Both can be used for splitting decision trees, but they may lead to slightly different splits."
      ],
      "metadata": {
        "id": "Ixe_qaaeTLea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What is the mathematical explanation behind Decision Trees?\n"
      ],
      "metadata": {
        "id": "As4LmuHgTPba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree algorithm recursively partitions the data based on a feature that minimizes impurity or maximizes information gain. The decision tree splits the dataset at each node using a feature and continues this process recursively to create branches until it reaches a leaf node."
      ],
      "metadata": {
        "id": "Uir9Fo-ATQ07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is Pre-Pruning in Decision Trees?\n"
      ],
      "metadata": {
        "id": "HmNh-ZuFTRNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Pruning involves stopping the growth of the Decision Tree early, before it perfectly fits the training data. This is done by setting criteria such as a maximum depth, minimum samples per leaf, or minimum samples per split. The goal is to avoid overfitting."
      ],
      "metadata": {
        "id": "_B6fboNjTSjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is Post-Pruning in Decision Trees?"
      ],
      "metadata": {
        "id": "7qjM_EAbTT1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post-Pruning involves growing the Decision Tree fully and then trimming branches that provide little to no improvement in classification accuracy. The idea is to remove nodes that do not significantly contribute to the predictive power of the tree."
      ],
      "metadata": {
        "id": "6_m8QD7kTV9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the difference between Pre-Pruning and Post-Pruning?"
      ],
      "metadata": {
        "id": "tEyNkGjNTWkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Pruning stops the tree from growing too complex by applying constraints before the tree reaches its maximum depth.\n",
        "\n",
        "Post-Pruning allows the tree to grow fully and then reduces its complexity by cutting branches that are unnecessary."
      ],
      "metadata": {
        "id": "ZUvwZha4TYNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is a Decision Tree Regressor?"
      ],
      "metadata": {
        "id": "TX8sRnyXTaFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree Regressor is a variation of Decision Trees used for regression tasks. Instead of predicting class labels, it predicts continuous values by partitioning the data based on features and fitting a constant value to each region of the tree."
      ],
      "metadata": {
        "id": "ZFLziJw4TbkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What are the advantages and disadvantages of Decision Trees?"
      ],
      "metadata": {
        "id": "d2K0PALGTczE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages:\n",
        "* Easy to interpret and visualize.\n",
        "* Handles both categorical and numerical data.\n",
        "* Can capture non-linear relationships.\n",
        "* No need for feature scaling.\n",
        "\n",
        "Disadvantages:\n",
        "* Prone to overfitting, especially with deep trees.\n",
        "* Sensitive to small variations in the data.\n",
        "* Can be biased towards features with more levels."
      ],
      "metadata": {
        "id": "bWfxkewRTeFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. How does a Decision Tree handle missing values?\n"
      ],
      "metadata": {
        "id": "gUIhNPG5TnpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees can handle missing values in two ways:\n",
        "\n",
        "By assigning a default class: If a feature is missing, the model can predict the class based on the majority class or the mean of a feature.\n",
        "\n",
        "By splitting the dataset based on missing values: Some implementations (like sklearn) split the data based on missing and non-missing values."
      ],
      "metadata": {
        "id": "lqeDeb8gTqnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How does a Decision Tree handle categorical features?\n"
      ],
      "metadata": {
        "id": "cjBH8hOdTrKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees handle categorical features by selecting the best feature split that divides the data into subsets. For categorical variables, they check for the best split by evaluating the information gain or impurity reduction when different categories are selected as a splitting criterion."
      ],
      "metadata": {
        "id": "wNiqSMAQTuWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What are some real-world applications of Decision Trees?\n"
      ],
      "metadata": {
        "id": "qTDg-a3KTwr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Medical diagnosis: Predicting diseases based on patient data.\n",
        "* Customer segmentation: Classifying customers based on purchasing behavior.\n",
        "* Fraud detection: Identifying fraudulent transactions.\n",
        "* Loan approval: Determining whether a loan application should be approved based on financial data."
      ],
      "metadata": {
        "id": "TPxgcZvLTzMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical Questions"
      ],
      "metadata": {
        "id": "kVvkI3I9T7dA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy"
      ],
      "metadata": {
        "id": "zzEWLSGlT-Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh5Ud0gbUPTa",
        "outputId": "28e449a0-8e7f-4770-db18-ac96e0a87d14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the\n",
        "feature importance"
      ],
      "metadata": {
        "id": "OmjrbaG_UT2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier using Gini Impurity\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"Feature Importances:\", clf.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i49jZ8hTUV59",
        "outputId": "f4c224b4-b160-490d-d9ad-bfb020276598"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances: [0.         0.01911002 0.89326355 0.08762643]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the\n",
        "model accuracy"
      ],
      "metadata": {
        "id": "PvNxfNiaUZUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier using Entropy\n",
        "clf = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZNW0-VkUa5J",
        "outputId": "9329878b-a4b0-4233-dc58-0ffc995b44da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean\n",
        "Squared Error (MSE)"
      ],
      "metadata": {
        "id": "Ovwm2tQwUeL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California housing dataset\n",
        "california_housing = fetch_california_housing()\n",
        "X = california_housing.data\n",
        "y = california_housing.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate MSE\n",
        "y_pred = regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83ezXgNkUfd2",
        "outputId": "dc5474d1-8583-463c-b13a-713f7c25a2f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz*"
      ],
      "metadata": {
        "id": "Bh_4wyE1U1Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the decision tree\n",
        "dot_data = export_graphviz(clf, out_file=None, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree\", view=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AZ1c33_DU2OE",
        "outputId": "6c508ccf-09f0-4660-cf22-1b44727c66a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its\n",
        "accuracy with a fully grown tree"
      ],
      "metadata": {
        "id": "H_0choZ8U4j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier with max_depth=3\n",
        "clf_3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf_3.fit(X_train, y_train)\n",
        "y_pred_3 = clf_3.predict(X_test)\n",
        "accuracy_3 = accuracy_score(y_test, y_pred_3)\n",
        "\n",
        "# Train a fully grown Decision Tree Classifier\n",
        "clf_full = DecisionTreeClassifier(random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "print(f\"Accuracy of max_depth=3 tree: {accuracy_3:.2f}\")\n",
        "print(f\"Accuracy of fully grown tree: {accuracy_full:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8IL2wlJVBn7",
        "outputId": "c4f97164-cad8-43a8-fda2-856274da9d33"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of max_depth=3 tree: 1.00\n",
            "Accuracy of fully grown tree: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its\n",
        "accuracy with a default tree"
      ],
      "metadata": {
        "id": "8-RV16sTVDma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier with min_samples_split=5\n",
        "clf_min_split = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "clf_min_split.fit(X_train, y_train)\n",
        "y_pred_min_split = clf_min_split.predict(X_test)\n",
        "accuracy_min_split = accuracy_score(y_test, y_pred_min_split)\n",
        "\n",
        "# Train a default Decision Tree Classifier\n",
        "clf_default = DecisionTreeClassifier(random_state=42)\n",
        "clf_default.fit(X_train, y_train)\n",
        "y_pred_default = clf_default.predict(X_test)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "\n",
        "print(f\"Accuracy with min_samples_split=5: {accuracy_min_split:.2f}\")\n",
        "print(f\"Accuracy with default tree: {accuracy_default:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LF3vNMAVGc8",
        "outputId": "5835770e-bfef-4501-8bf3-ba371089d074"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with min_samples_split=5: 1.00\n",
            "Accuracy with default tree: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its\n",
        "accuracy with unscaled data"
      ],
      "metadata": {
        "id": "zqAUScInVIpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Decision Tree Classifier on scaled data\n",
        "clf_scaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = clf_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Train Decision Tree Classifier on unscaled data\n",
        "clf_unscaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_unscaled.fit(X_train, y_train)\n",
        "y_pred_unscaled = clf_unscaled.predict(X_test)\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "\n",
        "print(f\"Accuracy with scaled data: {accuracy_scaled:.2f}\")\n",
        "print(f\"Accuracy with unscaled data: {accuracy_unscaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBC7FxX9VMzC",
        "outputId": "90e5f81e-e1b1-425d-e053-2b0b184e4bc1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with scaled data: 1.00\n",
            "Accuracy with unscaled data: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass\n",
        "classification*"
      ],
      "metadata": {
        "id": "zZaw8OKuVO3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier using One-vs-Rest strategy\n",
        "ovr_clf = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
        "ovr_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred_ovr = ovr_clf.predict(X_test)\n",
        "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
        "print(f\"Accuracy with One-vs-Rest: {accuracy_ovr:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_IJNSpIVbFZ",
        "outputId": "81958252-b884-41cb-ed02-2daddfb429b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with One-vs-Rest: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores"
      ],
      "metadata": {
        "id": "_WguCk1ZVdXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Display the feature importance scores\n",
        "print(\"Feature Importance Scores:\", clf.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWEL0YceVkDb",
        "outputId": "4102b57d-348d-456f-caf9-e56398641e39"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores: [0.         0.01911002 0.89326355 0.08762643]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance\n",
        "with an unrestricted tree"
      ],
      "metadata": {
        "id": "cobNZvTnVlxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load Boston housing dataset\n",
        "california_housing = fetch_california_housing()\n",
        "X = california_housing.data\n",
        "y = california_housing.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor with max_depth=5\n",
        "regressor_max_depth = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "regressor_max_depth.fit(X_train, y_train)\n",
        "y_pred_max_depth = regressor_max_depth.predict(X_test)\n",
        "mse_max_depth = mean_squared_error(y_test, y_pred_max_depth)\n",
        "\n",
        "# Train an unrestricted Decision Tree Regressor\n",
        "regressor_unrestricted = DecisionTreeRegressor(random_state=42)\n",
        "regressor_unrestricted.fit(X_train, y_train)\n",
        "y_pred_unrestricted = regressor_unrestricted.predict(X_test)\n",
        "mse_unrestricted = mean_squared_error(y_test, y_pred_unrestricted)\n",
        "\n",
        "print(f\"Mean Squared Error with max_depth=5: {mse_max_depth:.2f}\")\n",
        "print(f\"Mean Squared Error with unrestricted tree: {mse_unrestricted:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oFEDqnRVsLl",
        "outputId": "c3c44598-f022-4257-ae86-00309aec0538"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error with max_depth=5: 0.52\n",
            "Mean Squared Error with unrestricted tree: 0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and\n",
        "visualize its effect on accuracy"
      ],
      "metadata": {
        "id": "3QWa6s6ZWLBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy_before_pruning = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Apply Cost Complexity Pruning (CCP)\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "clfs = []\n",
        "\n",
        "# Train trees for each alpha and evaluate\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf_pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
        "    clf_pruned.fit(X_train, y_train)\n",
        "    clfs.append(clf_pruned)\n",
        "\n",
        "# Predict and evaluate accuracy after pruning\n",
        "accuracies_after_pruning = [accuracy_score(y_test, clf.predict(X_test)) for clf in clfs]\n",
        "\n",
        "# Display the results\n",
        "print(f\"Accuracy before pruning: {accuracy_before_pruning:.2f}\")\n",
        "print(f\"Best Accuracy after pruning: {max(accuracies_after_pruning):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAH6aj92WMWJ",
        "outputId": "be800908-37e1-4a43-f648-6fe07bc8e3a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy before pruning: 1.00\n",
            "Best Accuracy after pruning: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision,\n",
        "Recall, and F1-Score"
      ],
      "metadata": {
        "id": "Qw_5Ju42WOkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate using Precision, Recall, and F1-Score\n",
        "y_pred = clf.predict(X_test)\n",
        "precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cHdLe-fWSa_",
        "outputId": "52316231-b6b6-4e26-c3d5-1fae7eaee493"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn"
      ],
      "metadata": {
        "id": "H-jkS7l1WXLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and create confusion matrix\n",
        "y_pred = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix using seaborn\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "--HNjp5mWYpV",
        "outputId": "ad93ede4-bfca-41a2-80ed-12c4cc6b46d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values\n",
        "for max_depth and min_samples_split."
      ],
      "metadata": {
        "id": "Dqo9W82FWb_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Set up parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best parameters and evaluate\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best Cross-Validation Score: {best_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk8fmX7tWZxj",
        "outputId": "e55a505a-0239-44e1-ccc4-fe9d8865e04f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 5, 'min_samples_split': 10}\n",
            "Best Cross-Validation Score: 0.94\n"
          ]
        }
      ]
    }
  ]
}