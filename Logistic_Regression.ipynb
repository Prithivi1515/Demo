{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6ejx+sHycnq3YKmMAW4Y6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prithivi1515/Demo/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression\n",
        "\n",
        "Theoretical Questions\n"
      ],
      "metadata": {
        "id": "d3j2bSQMFvLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n"
      ],
      "metadata": {
        "id": "HBgr5OziFyuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is a classification algorithm that predicts probabilities using a sigmoid function. Unlike Linear Regression (which predicts continuous values), it outputs values between 0 and 1 for binary classification."
      ],
      "metadata": {
        "id": "iq8wSGlTF9Nq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the mathematical equation of Logistic Regression?\n"
      ],
      "metadata": {
        "id": "Vw6Ern_pF9w2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "P(y=1)= 1/\n",
        "1+e\n",
        "−(β\n",
        "0\n",
        "​\n",
        " +β\n",
        "1\n",
        "​\n",
        " X\n",
        "1\n",
        "​\n",
        " +⋯+β\n",
        "n\n",
        "​\n",
        " X\n",
        "n\n",
        "​\n",
        " )\n",
        "\n"
      ],
      "metadata": {
        "id": "hsjjOq70GAPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Why do we use the Sigmoid function in Logistic Regression?\n"
      ],
      "metadata": {
        "id": "1X_LkSf1GDrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sigmoid function maps real numbers to [0,1], enabling probability interpretation and ensuring differentiability for optimization.\n",
        "\n"
      ],
      "metadata": {
        "id": "NOJf2AOJGMkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the cost function of Logistic Regression?\n"
      ],
      "metadata": {
        "id": "dbiSQWmHGOE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log Loss (Cross-Entropy Loss):\n",
        "−\n",
        "1/\n",
        "m\n",
        "∑\n",
        "i\n",
        "=\n",
        "1\n",
        "m\n",
        "[\n",
        "y\n",
        "i\n",
        "log\n",
        "⁡\n",
        "(\n",
        "p\n",
        "i\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "−\n",
        "y\n",
        "i\n",
        ")\n",
        "log\n",
        "⁡\n",
        "(\n",
        "1\n",
        "−\n",
        "p\n",
        "i\n",
        ")\n",
        "]"
      ],
      "metadata": {
        "id": "lTDYj6MKMIjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is Regularization in Logistic Regression? Why is it needed?\n"
      ],
      "metadata": {
        "id": "uJ5H9j4UMYod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization (L1/L2) adds penalty terms to prevent overfitting by controlling model complexity.\n",
        "\n"
      ],
      "metadata": {
        "id": "aojRO5LhMadr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "AA3ORHO2MbkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso (L1): Adds absolute coefficient penalties; can zero out features.\n",
        "\n",
        "Ridge (L2): Adds squared coefficient penalties; shrinks coefficients.\n",
        "\n",
        "Elastic Net: Combines L1 and L2 penalties."
      ],
      "metadata": {
        "id": "grhRl3DVMdj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n"
      ],
      "metadata": {
        "id": "X-6lyJTtMe4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When features are correlated or both feature selection and shrinkage are needed.\n",
        "\n"
      ],
      "metadata": {
        "id": "00NRtJuSMglY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the impact of the regularization parameter (λ) in Logistic Regression?\n"
      ],
      "metadata": {
        "id": "phFt-ibeMiD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher λ increases regularization strength, reducing overfitting but risking underfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "gZbpD0PNMkbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Key assumptions of Logistic Regression?\n",
        "\n"
      ],
      "metadata": {
        "id": "m_mHd2d2Mlnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary outcome.\n",
        "\n",
        "Independent observations.\n",
        "\n",
        "No severe multicollinearity.\n",
        "\n",
        "Linearity between features and log-odds."
      ],
      "metadata": {
        "id": "vrbm83SaMnvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Alternatives to Logistic Regression for classification tasks?\n"
      ],
      "metadata": {
        "id": "YD4HGBp2MpV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM, Decision Trees, Random Forests, K-NN, Naive Bayes.\n",
        "\n"
      ],
      "metadata": {
        "id": "lLhA31zLMsEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Classification Evaluation Metrics?\n"
      ],
      "metadata": {
        "id": "5RTAeJQ3Msf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy, Precision, Recall, F1-Score, ROC-AUC, Confusion Matrix.\n",
        "\n"
      ],
      "metadata": {
        "id": "fHcwX1szMuOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How does class imbalance affect Logistic Regression?\n"
      ],
      "metadata": {
        "id": "51sSksYNMvWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biases the model toward the majority class. Mitigate with class weights or resampling.\n",
        "\n"
      ],
      "metadata": {
        "id": "95jgz6llMx4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Hyperparameter Tuning in Logistic Regression?\n"
      ],
      "metadata": {
        "id": "BeyD0ma5Mygn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing parameters like C (inverse of λ), penalty, and solver.\n",
        "\n"
      ],
      "metadata": {
        "id": "DNwCMsBvM0nH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Different solvers in Logistic Regression? Which one should be used?\n",
        "\n"
      ],
      "metadata": {
        "id": "8h-jt8MGM19J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "liblinear (small datasets).\n",
        "\n",
        "saga (large datasets).\n",
        "\n",
        "lbfgs (multiclass)."
      ],
      "metadata": {
        "id": "SGNaD6WHM3v4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How is Logistic Regression extended for multiclass classification?\n"
      ],
      "metadata": {
        "id": "PXvIeYe-M5AN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-vs-Rest (OvR) or Softmax (multinomial regression).\n",
        "\n"
      ],
      "metadata": {
        "id": "qF2ZWR5pM68J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Advantages and Disadvantages of Logistic Regression?\n",
        "\n"
      ],
      "metadata": {
        "id": "LI-n_ilCM8Lh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pros: Simple, interpretable, outputs probabilities.\n",
        "\n",
        "Cons: Assumes linearity, struggles with non-linear data."
      ],
      "metadata": {
        "id": "6dIJObb0M9_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Use cases of Logistic Regression?\n"
      ],
      "metadata": {
        "id": "aq6QQ2uPM_9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spam detection, credit risk assessment, medical diagnosis.\n",
        "\n"
      ],
      "metadata": {
        "id": "JY3abxaoNDKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Difference between Softmax Regression and Logistic Regression?\n"
      ],
      "metadata": {
        "id": "nzix6QyHNEv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax handles multiclass directly; Logistic is for binary classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "9JQUpDuaNGjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Choosing OvR vs Softmax?\n"
      ],
      "metadata": {
        "id": "FLQQtoRoNHnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use OvR for non-exclusive classes; Softmax for mutually exclusive multiclass.\n",
        "\n"
      ],
      "metadata": {
        "id": "T0vhKgAPNKB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How to interpret coefficients in Logistic Regression?\n"
      ],
      "metadata": {
        "id": "zHfgTvbdNLqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coefficients represent log-odds change. Exponentiate for odds ratios.\n",
        "\n"
      ],
      "metadata": {
        "id": "9qSmTm-wNNWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical Questions"
      ],
      "metadata": {
        "id": "sY0qYY0tNNyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Basic Logistic Regression:\n"
      ],
      "metadata": {
        "id": "kbhAcLsxNRGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od6R7pTPNSiy",
        "outputId": "6739b664-3b15-45d6-d5df-1aa9ff302fd7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. L1 Regularization (Lasso):"
      ],
      "metadata": {
        "id": "ytZ4Rh2YNtY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"L1 Accuracy: {model.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X74vbip6Nr8I",
        "outputId": "b75e36ca-d713-46be-c9f4-3f729330a220"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. L2 Regularization (Ridge):"
      ],
      "metadata": {
        "id": "ZrIChrmzNxcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l2')\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"L2 Accuracy: {model.score(X_test, y_test):.2f}\")\n",
        "print(\"Coefficients:\", model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cJGHGenNv0F",
        "outputId": "7d419781-391c-4275-f2db-93959b65addb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 Accuracy: 0.98\n",
            "Coefficients: [[-0.37852322  0.86951232 -2.26556023 -0.9703293 ]\n",
            " [ 0.4541088  -0.33342475 -0.15068292 -0.7236711 ]\n",
            " [-0.07558558 -0.53608756  2.41624315  1.6940004 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Elastic Net Regularization:"
      ],
      "metadata": {
        "id": "W-aWIWorN0Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"ElasticNet Accuracy: {model.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcnH5oeVNy4u",
        "outputId": "34fb8b0e-5476-4e89-a009-4edc1c038262"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet Accuracy: 0.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Multiclass Classification (OvR):"
      ],
      "metadata": {
        "id": "3x2iB5xGN3kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(multi_class='ovr')\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"OvR Accuracy: {model.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPAx69LtN1mW",
        "outputId": "76c0681f-a321-4422-e86e-4916e48b5fbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvR Accuracy: 0.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. GridSearchCV for Hyperparameter Tuning:"
      ],
      "metadata": {
        "id": "IaK3h1q3N66Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "grid = GridSearchCV(model, param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(f\"Best Params: {grid.best_params_}, Accuracy: {grid.best_score_:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7OD-tPdN5L8",
        "outputId": "69a6a340-899a-423c-beff-8ebff897960d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'C': 10, 'penalty': 'l1'}, Accuracy: 0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Stratified K-Fold Cross-Validation:"
      ],
      "metadata": {
        "id": "l4eAVwKgN-rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "scores = cross_val_score(model, X, y, cv=skf)\n",
        "print(f\"Average Accuracy: {scores.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ri524G6N8aJ",
        "outputId": "5d8944b4-76e4-4ba2-ed55-a42ef732e6f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Load CSV and Evaluate:"
      ],
      "metadata": {
        "id": "n7WpPZ82OB5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "# Convert the data into a pandas DataFrame\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Add the target column to the dataframe\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Features (all columns except the target)\n",
        "X = df[iris.feature_names]\n",
        "\n",
        "# Target (the last column)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optionally, scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZqRA8ytOACa",
        "outputId": "47925ba0-c57e-4855-c33a-d125a112e895"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. RandomizedSearchCV for Hyperparameter Tuning\n"
      ],
      "metadata": {
        "id": "zCzjzNwWOzAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Convert the data into a pandas DataFrame\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Add the target column to the dataframe\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Features (all columns except the target)\n",
        "X = df[iris.feature_names]\n",
        "\n",
        "# Target (the last column)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Define the hyperparameters for tuning\n",
        "param_dist = {\n",
        "    'C': np.logspace(-4, 4, 20),  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],      # Regularization type\n",
        "    'solver': ['liblinear', 'saga']  # Solvers\n",
        "}\n",
        "\n",
        "# Set up the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=100, cv=5, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the model using RandomizedSearchCV\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Make predictions with the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Best Parameters: {best_params}')\n",
        "print(f'Accuracy of the best model: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akAORfTWOECV",
        "outputId": "67d915da-9cb7-4fbf-b90a-6991ae46cb03"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 80 is smaller than n_iter=100. Running 80 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 0.23357214690901212}\n",
            "Accuracy of the best model: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. One-vs-One (OvO) Multiclass Logistic Regression\n"
      ],
      "metadata": {
        "id": "0Ht3l36OPCVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = OneVsOneClassifier(LogisticRegression())\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"OvO Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFrLzRkGO1uF",
        "outputId": "46ac12d4-0420-499f-c53e-fa18643ea635"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvO Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Confusion Matrix for Binary Classification"
      ],
      "metadata": {
        "id": "4kSgIKSePIBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "KSEUe9SSPFFq",
        "outputId": "90a29e32-b561-499a-c82c-d9bb636d0d52"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Precision, Recall, and F1-Score"
      ],
      "metadata": {
        "id": "bg4Tyk-IPMtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.2f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eqrClyjPJsW",
        "outputId": "bd907ce8-661a-4f24-e5d7-042545b60baf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.89\n",
            "Recall: 0.97\n",
            "F1-Score: 0.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Class Weights for Imbalanced Data"
      ],
      "metadata": {
        "id": "cc3xPnePPQMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Accuracy with Class Weights: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OVaFU_vPObv",
        "outputId": "328cc758-86d5-4a84-eb8a-c8f96719eebf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Class Weights: 0.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Titanic Dataset with Missing Values"
      ],
      "metadata": {
        "id": "3TPEYgJMPUiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Titanic dataset using seaborn\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Show the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Select the relevant columns\n",
        "df = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'survived']]\n",
        "\n",
        "# Encode 'sex' column: male -> 0, female -> 1\n",
        "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Handle missing values in the 'age' column using SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[['age']] = imputer.fit_transform(df[['age']])\n",
        "\n",
        "# Define the features (X) and target (y)\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "# Split the data into training and testing sets (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfWYxcj7PR7a",
        "outputId": "8f3d97b1-5e5e-453b-8d00-d92c32e0b1a1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "Accuracy: 80.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Feature Scaling (Standardization)"
      ],
      "metadata": {
        "id": "871r0HjPQdnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(f\"Accuracy with Scaling: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLgkmVPRPWN_",
        "outputId": "5f9e68a6-79b6-4e7b-9ede-d19e69a42d7e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Scaling: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. ROC-AUC Score"
      ],
      "metadata": {
        "id": "3CX5Y7wAQgPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQKQAWvXQfpc",
        "outputId": "26eaa045-5486-4a62-a8c5-c6867bc8da5c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Custom Learning Rate (C=0.5)"
      ],
      "metadata": {
        "id": "tL1bbLhBQlBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = LogisticRegression(C=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Accuracy with C=0.5: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN_Mz1e5Qj7y",
        "outputId": "69f840a0-4890-45eb-f682-20b002f25465"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Feature Importance from Coefficients"
      ],
      "metadata": {
        "id": "Wv1DgRidQr6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "importance = pd.DataFrame({'Feature': range(X.shape[1]), 'Coefficient': model.coef_[0]})\n",
        "print(importance.sort_values(by='Coefficient', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-nEJOuDQpkx",
        "outputId": "720ba94f-df7b-4b07-a233-45e60f175cf3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Feature  Coefficient\n",
            "1        1     0.966380\n",
            "0        0    -0.418274\n",
            "3        3    -1.084132\n",
            "2        2    -2.520825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Cohen’s Kappa Score"
      ],
      "metadata": {
        "id": "u8kK-wLmQvga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Cohen’s Kappa: {cohen_kappa_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5KICUOQQt18",
        "outputId": "72bddb04-f820-4712-b4e9-df6b86b37957"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen’s Kappa: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Precision-Recall Curve"
      ],
      "metadata": {
        "id": "R9Kat96FQznh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "RNN5H2Y3Qxyw",
        "outputId": "1d2fbc85-4343-4c14-fa8f-0a410689a681"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Compare Solvers (liblinear, saga, lbfgs)"
      ],
      "metadata": {
        "id": "hIGS9G4QQ5Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Accuracy with {solver}: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c9y7VmrQ7Td",
        "outputId": "1dc821a9-6438-4173-d6e4-b72c336f57cc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with liblinear: 0.96\n",
            "Accuracy with saga: 0.96\n",
            "Accuracy with lbfgs: 0.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Matthews Correlation Coefficient (MCC)"
      ],
      "metadata": {
        "id": "uauo5nZbQ9jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"MCC: {matthews_corrcoef(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_NAzqQ8Q1Rp",
        "outputId": "afeafaf8-2cca-4024-c41e-b5bf1eb5f816"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC: 0.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Impact of Feature Scaling"
      ],
      "metadata": {
        "id": "Jbuho5SqRBVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "# Without Scaling\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Accuracy without Scaling: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "# With Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(f\"Accuracy with Scaling: {accuracy_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJkZ9dJaQ_Tz",
        "outputId": "9768add2-4eed-4958-9217-2383da54893e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Scaling: 0.98\n",
            "Accuracy with Scaling: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Optimal C using Cross-Validation"
      ],
      "metadata": {
        "id": "jkBnPl3eREo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "model = LogisticRegression()\n",
        "grid = GridSearchCV(model, param_grid, cv=5)\n",
        "grid.fit(X, y)\n",
        "print(f\"Optimal C: {grid.best_params_['C']}, Best Accuracy: {grid.best_score_:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvdgn62ARC5I",
        "outputId": "4c22990f-8477-45c6-c67a-d00e9d3ccb67"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C: 10, Best Accuracy: 0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Save and Load Model using Joblib"
      ],
      "metadata": {
        "id": "3cj5mko1RJB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "import joblib\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "joblib.dump(model, 'logistic_model.pkl')\n",
        "loaded_model = joblib.load('logistic_model.pkl')\n",
        "print(f\"Model Accuracy: {loaded_model.score(X, y):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtYY7Q1yRGZp",
        "outputId": "c681cde5-7f00-497c-ae63-5ab578447c0f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}